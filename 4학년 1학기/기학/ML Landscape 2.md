- 머신러닝 시스템 분류 기준
	- 사람의 지도/감독 하에 훈련하는가?
		- 지도: 훈련 데이터에 레이블(타깃)이라는 원하는 답이 포함됨
			- 분류
				- 스팸 분류
			- 회귀
				- 주어진 입력과 출력간의 관계를 모델링
				- 연속적인 값을 예측하는데 사용
		- 비지도: 레이블 없는 훈련 데이터를 사용해 스스로 학습
			- 군집
				- 레이블이 없는 데이터 분석해 비슷한 몇개의 그룹으로 나누기
			- 시각화
				- 레이블이 없는 고차원 데이터(여러 특성)를 분석해 도식화
				- 원본의 군집들이 시각화된 plot에서도 분리되어 보이게
			- 차원 축소
				- 데이터 손실 최소화하며 차원(특성 수) 간소화
				- 상관관계가 있는 여러 특성을 하나로 합치는 특성 추출(주행거리 + 연식 = 마모 정도)
				- 알고리즘 성능 향상
			- 이상 탐지 vs 특이치 탐지
				- 이상 탐지
					- 정상 샘플 훈련 후 새 샘플의 정상 여부 확인
				- 특이치 탐지
					- clean 데이터 학습 후 훈련 데이터와 달라 보이는 데이터 탐지
					- 탐지하고자 하는 어떤 샘플도 훈련 데이터셋에 포함하면 안됨
				- 수천장의 강아지 사진 중 1%가 치와와 일때
					- 샘플에 치와와가 포함되어있으므로 특이치탐지 x
					- 1%이므로 이상치로 감지 가능
			- 연관 규칙
				- 특성 간 흥미로운 관계 찾기
				- 바베큐와 감자를 구매한 고객이 스테이크를 구매하는 경향 발견
				  → 세 상품을 가까이 진열
		- 준지도: 훈련 데이터셋이 일부만 레이블됨
			- 지도 학습과 비지도 학습을 혼용
				- 유사한 특성의 샘플끼리 군집을 분류
				- 레이블 데이터를 토대로 언레이블 데이터 레이블링 수행
				- 모두 레이블 되면 지도 학습 실행
		- 강화
			- 훈련대상 : 에이전트
			- 에이전트는 환경을 관찰해, 정책에 따라 취할 행동을 결정해 실행
			- 결과로 보상과 벌점이 주어지며, 에이전트는 보상을 강화하는 방식으로 정책을 수정해나감
			- 알파고
	- 실시간으로 주어지는 데이터에 대한 점진적 학습이 가능한가?
		- 온라인
			- 미니 배치 단위로 점진적 훈련
			- 각 학습 단계가 빠르고 비용이 적으며 새로운 데이터 바로 학습 가능
			- 극도로 빠른 변화에 스스로 적응해야하는 시스템, 가용한 자원 제한적일 때, 메모리에 로딩될 수 없는 큰 데이터셋 학습에 적합 (주식 가격 예측)
			- 나쁜 데이터 주입 시 성능 점진적 저하
			- 지속적인 모니터링 필요
		- 배치
			- 점진적 학습 불가능
			- 가용한 훈련 데이터셋 전체를 사용해 오프라인 훈련
			- 많은 시간과 컴퓨팅 자원 요구 
			- 새로운 데이터 학습하려면 기존 셋에 훈련할 샘플이 추가된 전체 데이터를 사용해 다시 훈련해야 함
	- 훈련모델의 일반화 방식에 따른 구분(주어진 새로운 데이터에 대해 예측)
		- 사례 기반
			- 훈련 샘플을 기억하는 것이 훈련의 전부
			- 주어진 샘플에 대한 예측을 위해 학습된 샘플과의 유사도 측정 
			- ![[Pasted image 20240424032014.png]]
		- 모델 기반
			- 훈련셋을 사용해 모델 훈련
			- 훈련셋의 패턴에 맞도록 훈련 과정에서 모델 파라미터 조정
			- 훈련된 모델을 사용해 새로운 인스턴스에 대한 예측 수행
			- ![[Pasted image 20240424032059.png]]
			- 선형 모델 학습
				- 특정 국가의 1인당 GDP 주어졌을 때 삶의 만족도 예측하는 선형 모델
				- ![[Pasted image 20240424032234.png]]
				- 쎄타 = 모델 파라미터
				- 훈련 과정 통해 훈련 데이터에 가장 잘 맞는 최선의 모델 파라미터를 찾아야 함
				- 선택된 쎄타 값에 대해 선형 모델 성능 평가하고 성능을 향상 시키는 방향으로 모델파라미터 조정 이루어짐. 최적값 찾을 때 까지 반복
- 분류 기준은 조합 가능
	- 스팸 필터 : 지도 + 온라인 + 모델 기반
		- 이메일이 스팸인지 햄인지에 대한 레이블이 포함
		- 학습된 모델이 새 이메일의 레이블(스팸 or 햄) 예측
- 머신 러닝의 주요 도전 과제
	- 데이터 문제
		- 훈련 데이터 부족
		- 대표성 없는 훈련 데이터
			- 샘플링 노이즈 : 훈련 데이터셋에 추가된 대표성 없는 데이터
			- 샘플링 편향 : 표본 추출 방법이 잘못 되어 한쪽으로 쏠린 대표성 없는 데이터
			- ![[Pasted image 20240424032620.png]]
		- 데이터 정제 과정의 필요성
			- 많은 이상치, 노이즈를 포함하는 훈련셋은 garbage in, garbage out
			- 데이터 정제 과정
				- 이상치인 경우 데이터를 보정하거나 무시
				- 일부 특성값 누락인 경우
					- 해당 특성 또는 샘플 제외
					- 누락된 특성값을 평균값 등으로 채움
					- 해당 특성을 포함시킨 경우와 아닌 경우로 각기 모델 훈련 후 성능 비교
		- 특성 공학
			- 해결 문제에 관련성이 높은 특성 찾는게 중요
			- 특성 선택
				- 문제 해결에 유용한 특성 선택
			- 특성 추출
				- 연관된 두가지 이상 특성 조합해 새 특성 생성
	- 알고리즘 문제
		- 과대 적합
			- ![[Pasted image 20240424033351.png]]
			- 훈련셋에 모델이 지나치게 fitting 되어 새로운 샘플에 대한 예측, 일반화 성능이 떨어짐
			- 새로운 샘플에 대한 예측 성능이 떨어지는 경우
			- 주어진 샘플보다 고차원의 모델을 도출하려 할때 발생
			  → 예시는 일차 회귀 모델이 아닌 고차원의 모델을 도출하려 했다가 발생
			- 규제 (과대적합 완화)
				- 훈련 중 모델 파라미터가 조정되는 과정에서 규제 적용
				- 규제는 모델이 훈련 데이터에 덜 민감하게 반응하도록 유도
				- 훈련 데이터의 패턴을 덜 반영하는 반면 새로운 샘플에 대한 일반화 성능은 높음
		- 과소 적합
			- ![[Pasted image 20240424033753.png]]
			- 주어진 훈련 데이터에 비해 너무 단순한 모델 선택에서 기인
			- 보다 많은 파라미터가 포함된 모델로 변경 필요
			- 보다 적합한 특성, 규제 완화
- 테스트와 검증
	- 모델 성능 평가
		- 훈련된 모델의 성능 평가를 위해 테스트셋 활용
		- 전체 데이터셋을 훈련셋(80%)과 테스트셋(20%)로 분할
		- 